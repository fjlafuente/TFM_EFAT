{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests as requests\n",
    "import json\n",
    "from requests.auth import HTTPBasicAuth\n",
    "import urllib"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction: APIs\n",
    "\n",
    "### REE APIs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_REE_generation(year): # -> REE API Only allows to extract data in a yearly basis\n",
    "\n",
    "    #First we get the response from REE (It only allow us to see one year each time)\n",
    "\n",
    "    response = requests.get(f\"https://apidatos.ree.es/es/datos/generacion/estructura-generacion?start_date={year}-01-01T00:00&end_date={year}-12-31T23:59&time_trunc=day\")\n",
    "    \n",
    "    #Data comes in a json with dictionaries inside. To access to the data we have to proccess it a little bit with json and dictionary methods.\n",
    "\n",
    "    generation = response.json()['included']\n",
    "    generation = pd.DataFrame.from_dict(generation)['attributes']\n",
    "    generation = pd.json_normalize(generation)\n",
    "    generation = generation[['title','values']]\n",
    "    \n",
    "    #We create a for loop in order to access to all data in the dicionary and to get the complete list for all the energetic resources\n",
    "    \n",
    "    typelist = list(generation['title'])\n",
    "    n= 0\n",
    "    data_consolidated = pd.DataFrame(columns= ['value', 'percentage', 'datetime', 'Type'])\n",
    "    \n",
    "    for value in generation['values']:\n",
    " \n",
    "        data = pd.DataFrame.from_dict(value)\n",
    "        data['Type'] = typelist[n]\n",
    "        n += 1\n",
    "        data_consolidated = pd.concat([data_consolidated, data])\n",
    "        \n",
    "    return data_consolidated\n",
    "\n",
    "\n",
    "def data_REE_demand(year): # -> REE API Only allows to extract data in a yearly basis\n",
    "\n",
    "     #First we get the response from REE (It only allow us to see one year each time)\n",
    "\n",
    "    demand = requests.get(f\"https://apidatos.ree.es/es/datos/demanda/evolucion?start_date={year}-01-01T00:00&end_date={year}-12-31T23:59&time_trunc=day\")\n",
    "\n",
    "    #Data comes in a json with dictionaries inside. To access to the data we have to proccess it a little bit with json and dictionary methods.\n",
    "\n",
    "    demand = demand.json()['included']\n",
    "    demand = pd.DataFrame.from_dict(demand)['attributes']\n",
    "    demand = pd.json_normalize(demand)\n",
    "    demand = demand['values']\n",
    "\n",
    "    #We create a for loop in order to access to all data in the dicionary and to get the complete list for all the energetic resources\n",
    "\n",
    "    n= 0\n",
    "    data_consolidated = pd.DataFrame(columns= ['value', 'percentage', 'datetime'])\n",
    "    \n",
    "    for value in demand:\n",
    " \n",
    "        data = pd.DataFrame.from_dict(value)\n",
    "        n += 1\n",
    "        data_consolidated = pd.concat([data_consolidated, data])\n",
    "    return data_consolidated\n",
    "\n",
    "def data_REE_potencia_instalada(year): # -> REE API Only allows to extract data in a yearly range as much, in monthly basis\n",
    "\n",
    "    #First we get the response from REE (It only allow us to see one year each time)\n",
    "\n",
    "    response = requests.get(f\"https://apidatos.ree.es/es/datos/generacion/potencia-instalada?start_date={year}-01-01T00:00&end_date={year}-12-31T23:59&time_trunc=day\")\n",
    "    \n",
    "    #Data comes in a json with dictionaries inside. To access to the data we have to proccess it a little bit with json and dictionary methods.\n",
    "\n",
    "    pinstalled = response.json()['included']\n",
    "    pinstalled = pd.DataFrame.from_dict(pinstalled)['attributes']\n",
    "    pinstalled = pd.json_normalize(pinstalled)\n",
    "    pinstalled = pinstalled[['title','values']]\n",
    "    \n",
    "    #We create a for loop in order to access to all data in the dicionary and to get the complete list for all the energetic resources\n",
    "    \n",
    "    typelist = list(pinstalled['title'])\n",
    "    n= 0\n",
    "    data_consolidated = pd.DataFrame(columns= ['value', 'percentage', 'datetime', 'Type'])\n",
    "    \n",
    "    for value in pinstalled['values']:\n",
    " \n",
    "        data = pd.DataFrame.from_dict(value)\n",
    "        data['Type'] = typelist[n]\n",
    "        n += 1\n",
    "        data_consolidated = pd.concat([data_consolidated, data])\n",
    "        \n",
    "    return data_consolidated\n",
    "\n",
    "def data_REE_generation_by_ccaa(year): #-> In order to know generation per CCAA per month\n",
    "\n",
    "    response = requests.get(f\"https://apidatos.ree.es/es/datos/generacion/estructura-generacion?start_date={year}-01-01T00:00&end_date={year}-12-31T23:59&time_trunc=day&all_ccaa=allCcaa\")\n",
    "    \n",
    "    #To convert response into a pd.DataFrame\n",
    "\n",
    "    generation_ccaa = response.json()['included']\n",
    "    generation_ccaa = pd.json_normalize(generation_ccaa)\n",
    "\n",
    "    #In order to include afterwards the reference for the CCAA when processing the file (it has dictionaries, lists... the proccess is complicated)\n",
    "    \n",
    "    ccaa_info = generation_ccaa[['geo_id', 'community_name']]\n",
    "    ccaa_info['ccaa'] = range(0,20)\n",
    "\n",
    "    #We access to 'content' key, where the information we want is, and create an empty dataframe to be fullfilled by iterating in the items\n",
    "\n",
    "    content = generation_ccaa['content'].to_dict()\n",
    "    total_data = pd.DataFrame(columns = ['ccaa', 'month', 'type', 'value', 'datetime', 'percentage'])\n",
    "\n",
    "    #Iteration will be based on keylist due to the response structure:\n",
    "\n",
    "    keylist = list(content.keys())\n",
    "    \n",
    "    for item in keylist:\n",
    "        data = content[item]\n",
    "        ccaa = item\n",
    "        for element in data:\n",
    "            data_selected = element['attributes']\n",
    "            data_selected = data_selected['values']\n",
    "            tech = element['type']\n",
    "            n = 0\n",
    "            for month in data_selected:\n",
    "                    n += 1\n",
    "                    df = pd.DataFrame(month, columns = ['value', 'percentage', 'datetime'], index = [n])\n",
    "                    df['type'] = tech\n",
    "                    df['ccaa'] = ccaa\n",
    "                    df['month'] = n\n",
    "                    total_data = pd.concat([total_data, df])\n",
    "\n",
    "    total_data_info = pd.merge(total_data , ccaa_info, on='ccaa', how = 'inner')\n",
    "\n",
    "    #We will already drop the information of 'total cca' as it won't be necessary, we already have it\n",
    "\n",
    "    data_filt = total_data_info.loc[total_data_info['ccaa'] != 19]\n",
    "\n",
    "    return data_filt\n",
    "\n",
    "\n",
    "def generation_by_CCAA_csv_file(year): # -> So we can save all years data in our project's directory\n",
    "    generation = data_REE_generation_by_ccaa(year)\n",
    "    generation.to_csv(f\"~/data/TFM_EFAT/TFM_EFAT/Data/Generation/Generation_by_CCAA/Generation_ccaa_{year}.csv\", index = False)\n",
    "\n",
    "\n",
    "def demand_csv_file(year): # -> So we can save all years data in our project's directory\n",
    "    demand = data_REE_demand(year)\n",
    "    demand.to_csv(f\"~/data/TFM_EFAT/TFM_EFAT/Data/Demand/Demand_{year}.csv\", index = False)\n",
    "\n",
    "def pinstalled_csv_file(year): # -> So we can save all years data in our project's directory\n",
    "    pinstalled = data_REE_potencia_instalada(year)\n",
    "    pinstalled.to_csv(f\"~/data/TFM_EFAT/TFM_EFAT/Data/Generation/PowerInstalled_{year}.csv\", index = False)\n",
    "\n",
    "def generation_csv_file(year): # -> So we can save all years data in our project's directory\n",
    "    generation = data_REE_generation(year)\n",
    "    generation.to_csv(f\"~/data/TFM_EFAT/TFM_EFAT/Data/Generation/Generation_{year}.csv\", index = False)    \n",
    "\n",
    "def aemet_data_api(year): # -> in order to get weather records from AEMET API\n",
    "\n",
    "    #It only allows to extract data in a mothly basis, so we have to create a for loop to solve it:\n",
    "\n",
    "    monthlist = ('01', '02', '03', '04', '05', '06', '07', '08', '09', '10', '11', '12')\n",
    "\n",
    "    #To see if year is a leap year:\n",
    "\n",
    "    feb = 'feb'\n",
    "\n",
    "    if year % 100 == 0:\n",
    "        if n % 400 == 0:\n",
    "            feb = '29'\n",
    "        else:\n",
    "            feb = '28'\n",
    "    else:\n",
    "        if year  % 4 == 0:\n",
    "            feb = '29'\n",
    "        else:\n",
    "            feb = '28'\n",
    "\n",
    "    monthlastday = {'01': '31', '02':feb, '03': '31', '04':'30', '05': '31', '06':'30', '07': '31', \n",
    "                    '08': '31', '09':'30', '10': '31', '11':'30', '12': '31'}\n",
    "\n",
    "    aemet_consolidated = pd.DataFrame(columns = ['fecha', 'indicativo', 'nombre', 'provincia', 'altitud', 'tmed', 'prec', 'tmin', 'horatmin', 'tmax',\n",
    "                                    'horatmax', 'dir', 'velmedia', 'racha', 'horaracha', 'sol', 'presMax', 'horaPresMax', 'presMin', 'horaPresMin'])\n",
    "\n",
    "\n",
    "    for month in monthlist:\n",
    "\n",
    "        fechaIniStr = f\"{year}-{month}-01T00:00:00UTC\" # str | Fecha Inicial (AAAA-MM-DDTHH:MM:SSUTC)\n",
    "        fechaFinStr = f\"{year}-{month}-{monthlastday[month]}T23:59:59UTC\"  # str | Fecha Final (AAAA-MM-DDTHH:MM:SSUTC)\n",
    "\n",
    "        url = f\"https://opendata.aemet.es/opendata/api/valores/climatologicos/diarios/datos/fechaini/{fechaIniStr}/fechafin/{fechaFinStr}/todasestaciones\"\n",
    "\n",
    "        #We need an API key that can be obtained from AEMET easily\n",
    "        \n",
    "        query = {\"api_key\":\"eyJhbGciOiJIUzI1NiJ9.eyJzdWIiOiJqYXZpZXIuZXNjYWxvbmlsbGFAaG90bWFpbC5jb20iLCJqdGkiOiJlNzgyMjg0Yy05YjI0LTQ5ZDktOWMwMS1kYjRlZjQwNjkxNDIiLCJpc3MiOiJBRU1FVCIsImlhdCI6MTY4MTE0MTIyNCwidXNlcklkIjoiZTc4MjI4NGMtOWIyNC00OWQ5LTljMDEtZGI0ZWY0MDY5MTQyIiwicm9sZSI6IiJ9.3flzKWh31FkeRBFex1xc4nIwEaQE1QPXoCpeicIluQU\"}\n",
    "\n",
    "        #We have to process the response from requests a little bit as the response is a url\n",
    "\n",
    "        response = requests.request(\"GET\", url,  params = query)\n",
    "\n",
    "        aemet_data = response.json()['datos']\n",
    "\n",
    "        aemet_data = urllib.request.urlopen(aemet_data)\n",
    "\n",
    "        # UTF-8 decoding, which is the standard, does not work with some characters of the response\n",
    "\n",
    "        aemet_data = json.loads(aemet_data.read().decode('latin-1'))\n",
    "        \n",
    "        aemet_data_df = pd.DataFrame.from_dict(aemet_data)\n",
    "\n",
    "        aemet_consolidated = pd.concat([aemet_consolidated, aemet_data_df])\n",
    "    \n",
    "    return aemet_consolidated\n",
    "\n",
    "def weather_csv_file(year): # -> So we can save all years data in our project's directory\n",
    "    weather = aemet_data_api(year)\n",
    "    weather.to_csv(f\"~/data/TFM_EFAT/TFM_EFAT/Data/Weather/Weather{year}.csv\", index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
